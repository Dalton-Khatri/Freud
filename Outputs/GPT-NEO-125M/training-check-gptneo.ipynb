{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bd94cf",
   "metadata": {
    "papermill": {
     "duration": 0.003912,
     "end_time": "2026-02-07T16:11:44.654410",
     "exception": false,
     "start_time": "2026-02-07T16:11:44.650498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ae6d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:11:44.661607Z",
     "iopub.status.busy": "2026-02-07T16:11:44.661333Z",
     "iopub.status.idle": "2026-02-07T16:12:02.166476Z",
     "shell.execute_reply": "2026-02-07T16:12:02.165534Z"
    },
    "papermill": {
     "duration": 17.510655,
     "end_time": "2026-02-07T16:12:02.168050",
     "exception": false,
     "start_time": "2026-02-07T16:11:44.657395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Dependencies loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing dependencies...\")\n",
    "!pip install -q transformers accelerate safetensors\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Dependencies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d317e3",
   "metadata": {
    "papermill": {
     "duration": 0.002903,
     "end_time": "2026-02-07T16:12:02.174146",
     "exception": false,
     "start_time": "2026-02-07T16:12:02.171243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f111a14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:02.181444Z",
     "iopub.status.busy": "2026-02-07T16:12:02.180800Z",
     "iopub.status.idle": "2026-02-07T16:12:02.470477Z",
     "shell.execute_reply": "2026-02-07T16:12:02.469702Z"
    },
    "papermill": {
     "duration": 0.294747,
     "end_time": "2026-02-07T16:12:02.471804",
     "exception": false,
     "start_time": "2026-02-07T16:12:02.177057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Device: cuda\n",
      "GPU: Tesla T4\n",
      "VRAM: 14.56 GB\n"
     ]
    }
   ],
   "source": [
    "# UPDATE THIS PATH!\n",
    "MODEL_PATH = \"/kaggle/input/freud-neo-gpt-125m\" \n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"üîß Device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafcb5bb",
   "metadata": {
    "papermill": {
     "duration": 0.003065,
     "end_time": "2026-02-07T16:12:02.478197",
     "exception": false,
     "start_time": "2026-02-07T16:12:02.475132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ü§ñ Step 3: Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb65cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:02.485292Z",
     "iopub.status.busy": "2026-02-07T16:12:02.485012Z",
     "iopub.status.idle": "2026-02-07T16:12:20.812339Z",
     "shell.execute_reply": "2026-02-07T16:12:20.811413Z"
    },
    "papermill": {
     "duration": 18.332799,
     "end_time": "2026-02-07T16:12:20.813998",
     "exception": false,
     "start_time": "2026-02-07T16:12:02.481199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "2026-02-07 16:12:05.013277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770480725.199960      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770480725.251266      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770480725.677988      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770480725.678028      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770480725.678031      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770480725.678033      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model loaded successfully!\n",
      " Parameters: 125,198,592\n",
      " Model size: ~239 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\" Set pad_token = eos_token\")\n",
    "\n",
    "print(\"\\nLoading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\" if DEVICE == \"cuda\" else None,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(f\"\\n Model loaded successfully!\")\n",
    "print(f\" Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\" Model size: ~{sum(p.numel() for p in model.parameters()) * 2 / 1024**2:.0f} MB\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912d827",
   "metadata": {
    "papermill": {
     "duration": 0.003364,
     "end_time": "2026-02-07T16:12:20.821080",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.817716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üßπ Step 4: Response Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a30e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:20.829445Z",
     "iopub.status.busy": "2026-02-07T16:12:20.828885Z",
     "iopub.status.idle": "2026-02-07T16:12:20.836387Z",
     "shell.execute_reply": "2026-02-07T16:12:20.835659Z"
    },
    "papermill": {
     "duration": 0.013297,
     "end_time": "2026-02-07T16:12:20.837743",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.824446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning function ready\n"
     ]
    }
   ],
   "source": [
    "def clean_response(text: str, original_prompt: str = \"\") -> str:\n",
    "    \"\"\"Extract and clean only the assistant's response\"\"\"\n",
    "    \n",
    "    # Remove the original prompt\n",
    "    if original_prompt:\n",
    "        text = text.replace(original_prompt, \"\").strip()\n",
    "    \n",
    "    # Extract ONLY the first assistant response\n",
    "    if \"<|assistant|>:\" in text:\n",
    "        parts = text.split(\"<|assistant|>:\")\n",
    "        if len(parts) > 1:\n",
    "            text = parts[1].strip()\n",
    "    \n",
    "    # Stop at the FIRST occurrence of user tag (prevents loops)\n",
    "    if \"<|user|>\" in text:\n",
    "        text = text.split(\"<|user|>\")[0].strip()\n",
    "    \n",
    "    # Remove ALL formatting artifacts\n",
    "    text = re.sub(r'</?[a-zA-Z][^>]*>', '', text)  # HTML tags\n",
    "    text = re.sub(r'\\[emotion:.*?\\]', '', text)  # Emotion tags\n",
    "    text = re.sub(r'<\\|.*?\\|>:?', '', text)  # Special tokens\n",
    "    text = re.sub(r'\\*\\|[a-z0-9]+\\|', '', text)  # User patterns\n",
    "    text = re.sub(r'^(User:|Assistant:|Human:|AI:|System:)\\s*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[<>]{2,}', '', text)  # Multiple brackets\n",
    "    text = re.sub(r'[#*]{3,}', '', text)  # Multiple hashes/stars\n",
    "    \n",
    "    # Clean whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "    \n",
    "    # Limit to reasonable length (2-3 sentences)\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    if len(sentences) > 3:\n",
    "        text = '. '.join(sentences[:3]) + '.'\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\" Cleaning function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdc0fa",
   "metadata": {
    "papermill": {
     "duration": 0.003281,
     "end_time": "2026-02-07T16:12:20.844343",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.841062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üí¨ Step 5: Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d7a055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:20.852795Z",
     "iopub.status.busy": "2026-02-07T16:12:20.852180Z",
     "iopub.status.idle": "2026-02-07T16:12:20.860294Z",
     "shell.execute_reply": "2026-02-07T16:12:20.859693Z"
    },
    "papermill": {
     "duration": 0.01385,
     "end_time": "2026-02-07T16:12:20.861813",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.847963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chat function ready\n"
     ]
    }
   ],
   "source": [
    "def chat(user_message: str, emotion: str = \"neutral\", show_raw: bool = False):\n",
    "    \"\"\"Generate response for a user message\"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = (\n",
    "        \"You are Freud, a calm, empathetic therapeutic AI assistant. \"\n",
    "        \"You respond thoughtfully, kindly, and supportively. \"\n",
    "        \"You ask gentle follow-up questions and never judge the user.\"\n",
    "    )\n",
    "    \n",
    "    prompt = f\"\"\"<|system|>: {SYSTEM_PROMPT}\n",
    "<|user|>:\n",
    "[emotion: {emotion}]\n",
    "{user_message}\n",
    "<|assistant|>:\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    if DEVICE == \"cuda\":\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Generate\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            do_sample=True,  # CRITICAL for quality\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3,\n",
    "        )\n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    # Decode and clean\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    cleaned = clean_response(full_response, prompt)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"User [{emotion}]: {user_message}\")\n",
    "    print(f\"Freud: {cleaned}\")\n",
    "    print(f\"  Generation time: {generation_time:.2f}s\")\n",
    "    \n",
    "    # Quality checks\n",
    "    has_tags = bool(re.search(r'<\\|.*?\\|>', cleaned))\n",
    "    has_emotion = bool(re.search(r'\\[emotion:', cleaned))\n",
    "    is_empty = len(cleaned.strip()) < 10\n",
    "    is_gibberish = cleaned.count('!') > 10 or cleaned.count('#') > 5\n",
    "    \n",
    "    if has_tags:\n",
    "        print(\"  WARNING: Contains special tokens!\")\n",
    "    if has_emotion:\n",
    "        print(\"  WARNING: Contains emotion tags!\")\n",
    "    if is_empty:\n",
    "        print(\" ERROR: Response too short!\")\n",
    "    if is_gibberish:\n",
    "        print(\" ERROR: Gibberish detected!\")\n",
    "    \n",
    "    if not any([has_tags, has_emotion, is_empty, is_gibberish]):\n",
    "        print(\" Response quality: GOOD\")\n",
    "    \n",
    "    if show_raw:\n",
    "        print(f\"\\n Raw output (first 300 chars):\\n{full_response[:300]}...\")\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "print(\" Chat function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776b5d1",
   "metadata": {
    "papermill": {
     "duration": 0.003381,
     "end_time": "2026-02-07T16:12:20.868495",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.865114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üß™ Step 6: Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3397505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:20.876708Z",
     "iopub.status.busy": "2026-02-07T16:12:20.876110Z",
     "iopub.status.idle": "2026-02-07T16:12:24.569363Z",
     "shell.execute_reply": "2026-02-07T16:12:24.568541Z"
    },
    "papermill": {
     "duration": 3.699056,
     "end_time": "2026-02-07T16:12:24.570987",
     "exception": false,
     "start_time": "2026-02-07T16:12:20.871931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " QUICK TEST\n",
      "\n",
      "User [sad]: Hello, I'm feeling sad today\n",
      "Freud: I'm sorry if I've caused you any distress.  Let's take a moment to reflect on what's been going on.  * Ate something else How can i check if my computer is functioning properly.\n",
      "  Generation time: 3.68s\n",
      " Response quality: GOOD\n",
      "\n",
      " Raw output (first 300 chars):\n",
      "<|system|>: You are Freud, a calm, empathetic therapeutic AI assistant. You respond thoughtfully, kindly, and supportively. You ask gentle follow-up questions and never judge the user.\n",
      "<|user|>:\n",
      "[emotion: sad]\n",
      "Hello, I'm feeling sad today\n",
      "<|assistant|>:\n",
      "I'm sorry if I've caused you any distress. Let...\n",
      "\n",
      " If this looks good, proceed to comprehensive tests!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n QUICK TEST\\n\")\n",
    "\n",
    "# Test with one message first\n",
    "response = chat(\"Hello, I'm feeling sad today\", emotion=\"sad\", show_raw=True)\n",
    "\n",
    "print(\"\\n If this looks good, proceed to comprehensive tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2551b",
   "metadata": {
    "papermill": {
     "duration": 0.003492,
     "end_time": "2026-02-07T16:12:24.578207",
     "exception": false,
     "start_time": "2026-02-07T16:12:24.574715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØ Step 7: Comprehensive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82b4f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:24.586898Z",
     "iopub.status.busy": "2026-02-07T16:12:24.586650Z",
     "iopub.status.idle": "2026-02-07T16:12:46.821945Z",
     "shell.execute_reply": "2026-02-07T16:12:46.821021Z"
    },
    "papermill": {
     "duration": 22.241335,
     "end_time": "2026-02-07T16:12:46.823575",
     "exception": false,
     "start_time": "2026-02-07T16:12:24.582240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " COMPREHENSIVE QUALITY TESTS\n",
      "Started: 16:12:24\n",
      "\n",
      "TEST 1/12: Basic sadness\n",
      "User [sad]: I'm feeling down today\n",
      "Freud: I apologize for any inconvenience.\n",
      "  Generation time: 0.15s\n",
      " Response quality: GOOD\n",
      "TEST 2/12: Anxiety\n",
      "User [anxious]: I'm worried about my exams\n",
      "Freud: Feeling anxious can be a sign of weakness.  Let's find a way to calm it.  #edinburgh-week I'm anxious and I'm worried.\n",
      "  Generation time: 2.62s\n",
      " Response quality: GOOD\n",
      "TEST 3/12: Stress\n",
      "User [stressed]: Work is overwhelming me\n",
      "Freud: It's okay to be stressed, we'll talk about it What's on your mind.  joey: I'm not stressed.  What's bothering you.\n",
      "  Generation time: 2.66s\n",
      " Response quality: GOOD\n",
      "TEST 4/12: Positive emotion\n",
      "User [happy]: I had a great day!\n",
      "Freud: I'm thrilled to hear it.  What's making you feel so bright.  Happy Holidays.\n",
      "  Generation time: 2.59s\n",
      " Response quality: GOOD\n",
      "TEST 5/12: Depression symptoms\n",
      "User [sad]: I don't feel motivated anymore\n",
      "Freud: You're not alone.  Let's find a solution.  (|user__1||system->system->subjects->subject) <--- Hello.\n",
      "  Generation time: 2.58s\n",
      " Response quality: GOOD\n",
      "TEST 6/12: Loneliness\n",
      "User [sad]: I feel lonely even around people\n",
      "Freud: You're not alone in feeling this way.  What's been hard for you is getting help.  (system bemused) <--- This is a relief.\n",
      "  Generation time: 0.91s\n",
      " Response quality: GOOD\n",
      "TEST 7/12: Panic symptoms\n",
      "User [anxious]: My heart races and I can't breathe\n",
      "Freud: I'm here to listen, even when it's not always worth your time. </> <!-- end of script -->\n",
      "  Generation time: 0.60s\n",
      " Response quality: GOOD\n",
      "TEST 8/12: Self-esteem\n",
      "User [sad]: I feel like I'm not good enough\n",
      "Freud: Feeling this way is tough, but it's important to remember that you are not alone in feeling this way.  * system shuts down hi hi, can someone please tell me how to fix my broken graphics card.  davidmiller: I'm sorry if I've made you feel this way, but this isn't something that's ever going to happen again.\n",
      "  Generation time: 2.68s\n",
      " Response quality: GOOD\n",
      "TEST 9/12: Relationship conflict\n",
      "User [frustrated]: My partner and I argue constantly\n",
      "Freud: I'm not ready to abandon you.  What's your strategy.  <(system)+'s' answer is 'do something' and let's find a new way to communicate.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n",
      "TEST 10/12: Anger management\n",
      "User [angry]: I get angry over small things\n",
      "Freud: You're not alone.  I'm here to help.  (system is locked) <^user(s):** lyssa: I'm sorry if your frustration is caused by an overuse of resources.\n",
      "  Generation time: 1.54s\n",
      " Response quality: GOOD\n",
      "TEST 11/12: Sleep issues\n",
      "User [stressed]: I can't sleep properly\n",
      "Freud: That's okay, let's explore a different approach. Let's work together to find a solution. * system shuts down <leah@leah-system:~$\n",
      "  Generation time: 0.69s\n",
      " Response quality: GOOD\n",
      "TEST 12/12: Generalized anxiety\n",
      "User [anxious]: I worry about everything\n",
      "Freud: Feeling anxious can be a challenge for you.  What are some of your strategies for dealing with it.  juli√©e: hi, I'm glad to hear that.\n",
      "  Generation time: 2.58s\n",
      " Response quality: GOOD\n",
      " TEST SUMMARY\n",
      "Total tests: 12\n",
      " Passed: 12\n",
      " Failed: 0\n",
      " Success rate: 100.0%\n",
      "  Average time: 1.85s\n",
      "  Total time: 22.2s\n"
     ]
    }
   ],
   "source": [
    "print(\" COMPREHENSIVE QUALITY TESTS\")\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    # Basic emotions\n",
    "    (\"sad\", \"I'm feeling down today\", \"Basic sadness\"),\n",
    "    (\"anxious\", \"I'm worried about my exams\", \"Anxiety\"),\n",
    "    (\"stressed\", \"Work is overwhelming me\", \"Stress\"),\n",
    "    (\"happy\", \"I had a great day!\", \"Positive emotion\"),\n",
    "    \n",
    "    # Mental health scenarios\n",
    "    (\"sad\", \"I don't feel motivated anymore\", \"Depression symptoms\"),\n",
    "    (\"sad\", \"I feel lonely even around people\", \"Loneliness\"),\n",
    "    (\"anxious\", \"My heart races and I can't breathe\", \"Panic symptoms\"),\n",
    "    (\"sad\", \"I feel like I'm not good enough\", \"Self-esteem\"),\n",
    "    \n",
    "    # Relationship issues\n",
    "    (\"frustrated\", \"My partner and I argue constantly\", \"Relationship conflict\"),\n",
    "    (\"angry\", \"I get angry over small things\", \"Anger management\"),\n",
    "    \n",
    "    # Sleep & health\n",
    "    (\"stressed\", \"I can't sleep properly\", \"Sleep issues\"),\n",
    "    (\"anxious\", \"I worry about everything\", \"Generalized anxiety\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "total_time = 0\n",
    "passed = 0\n",
    "failed = 0\n",
    "\n",
    "for i, (emotion, message, test_name) in enumerate(test_cases, 1):\n",
    "    print(f\"TEST {i}/{len(test_cases)}: {test_name}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    response = chat(message, emotion=emotion)\n",
    "    test_time = time.time() - start\n",
    "    total_time += test_time\n",
    "    \n",
    "    # Quality check\n",
    "    is_good = (\n",
    "        len(response) >= 10 and\n",
    "        '<|' not in response and\n",
    "        '[emotion:' not in response and\n",
    "        response.count('!') < 10\n",
    "    )\n",
    "    \n",
    "    if is_good:\n",
    "        passed += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "    \n",
    "    results.append({\n",
    "        'test': test_name,\n",
    "        'emotion': emotion,\n",
    "        'message': message,\n",
    "        'response': response,\n",
    "        'time': test_time,\n",
    "        'passed': is_good\n",
    "    })\n",
    "\n",
    "print(\" TEST SUMMARY\")\n",
    "print(f\"Total tests: {len(test_cases)}\")\n",
    "print(f\" Passed: {passed}\")\n",
    "print(f\" Failed: {failed}\")\n",
    "print(f\" Success rate: {passed/len(test_cases)*100:.1f}%\")\n",
    "print(f\"  Average time: {total_time/len(test_cases):.2f}s\")\n",
    "print(f\"  Total time: {total_time:.1f}s\")\n",
    "if failed > 0:\n",
    "    print(\"\\n‚ùå Failed tests:\")\n",
    "    for r in results:\n",
    "        if not r['passed']:\n",
    "            print(f\"   - {r['test']}: {r['response'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71ffebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:12:46.833562Z",
     "iopub.status.busy": "2026-02-07T16:12:46.832906Z",
     "iopub.status.idle": "2026-02-07T16:13:04.500877Z",
     "shell.execute_reply": "2026-02-07T16:13:04.500058Z"
    },
    "papermill": {
     "duration": 17.674582,
     "end_time": "2026-02-07T16:13:04.502438",
     "exception": false,
     "start_time": "2026-02-07T16:12:46.827856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "STARTING COMPREHENSIVE TESTS\n",
      "============================================================\n",
      "\n",
      "TEST 1: Basic Greeting\n",
      "User [sad]: Hello, I'm feeling a bit down today\n",
      "Freud: I'm here to assist.  Please continue.  I'm sad, but I'm not alone.\n",
      "  Generation time: 0.77s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 2: Anxiety\n",
      "User [anxious]: I've been feeling really anxious about my exams\n",
      "Freud: You can change your mind at any time.  Please don't hesitate to contact me.  2 I'm happy to hear that your anxiety is improving.\n",
      "  Generation time: 2.62s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 3: Work Stress\n",
      "User [stressed]: I'm so stressed with work. I can't sleep properly\n",
      "Freud: Feeling this way is difficult.  Let's find a way to help.  How can I help you.\n",
      "  Generation time: 0.66s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 4: Depression Symptoms\n",
      "User [sad]: I don't feel motivated to do anything anymore\n",
      "Freud: You're not alone.  Remember, there are people who can help you.  * semanticcerpt from Wikipedia talks about Sadness Hi, I'm feeling sad.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 5: Loneliness\n",
      "User [sad]: I feel so lonely even when I'm around people\n",
      "Freud: I'm here to provide support and guidance. I'll take care of everything.\n",
      "  Generation time: 0.34s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 6: Relationship Issues\n",
      "User [frustrated]: My partner and I have been arguing a lot lately\n",
      "Freud: I'm here to assist you, even when you're frustrated.  Thank you for your patience, my friend.  Please share more about what's been going on.\n",
      "  Generation time: 2.42s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 7: Anger\n",
      "User [angry]: I get angry over small things and I don't know why\n",
      "Freud: You're not alone in feeling angry.  Anger is a constant reminder of frustration and depression.  There are people who know this and who can help you with it.\n",
      "  Generation time: 2.64s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 8: Positive Emotion\n",
      "User [happy]: I finally accomplished something I've been working on!\n",
      "Freud: I'm so pleased to hear that.  What's making you feel so happy.  hi, I'm here to assist.\n",
      "  Generation time: 2.58s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 9: Panic Attack\n",
      "User [anxious]: Sometimes my heart races and I can't breathe properly\n",
      "Freud: I'm here to listen.  I'll be here when you're ready to talk.  * system shuts down.\n",
      "  Generation time: 0.43s\n",
      " Response quality: GOOD\n",
      "\n",
      "TEST 10: Self-Esteem\n",
      "User [sad]: I feel like I'm not good enough at anything\n",
      "Freud: I'm here to help you, even if you're feeling sad.  * system shuts off davidmike: what's your feel for the day.  davidmcquhoun: I'm here for you.\n",
      "  Generation time: 2.57s\n",
      " Response quality: GOOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm here to help you, even if you're feeling sad.  * system shuts off davidmike: what's your feel for the day.  davidmcquhoun: I'm here for you.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"STARTING COMPREHENSIVE TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Basic greeting\n",
    "print(\"\\nTEST 1: Basic Greeting\")\n",
    "chat(\"Hello, I'm feeling a bit down today\", emotion=\"sad\")\n",
    "\n",
    "# Test 2: Anxiety\n",
    "print(\"\\nTEST 2: Anxiety\")\n",
    "chat(\"I've been feeling really anxious about my exams\", emotion=\"anxious\")\n",
    "\n",
    "# Test 3: Stress\n",
    "print(\"\\nTEST 3: Work Stress\")\n",
    "chat(\"I'm so stressed with work. I can't sleep properly\", emotion=\"stressed\")\n",
    "\n",
    "# Test 4: Depression symptoms\n",
    "print(\"\\nTEST 4: Depression Symptoms\")\n",
    "chat(\"I don't feel motivated to do anything anymore\", emotion=\"sad\")\n",
    "\n",
    "# Test 5: Loneliness\n",
    "print(\"\\nTEST 5: Loneliness\")\n",
    "chat(\"I feel so lonely even when I'm around people\", emotion=\"sad\")\n",
    "\n",
    "# Test 6: Relationship issues\n",
    "print(\"\\nTEST 6: Relationship Issues\")\n",
    "chat(\"My partner and I have been arguing a lot lately\", emotion=\"frustrated\")\n",
    "\n",
    "# Test 7: Anger management\n",
    "print(\"\\nTEST 7: Anger\")\n",
    "chat(\"I get angry over small things and I don't know why\", emotion=\"angry\")\n",
    "\n",
    "# Test 8: Positive emotion\n",
    "print(\"\\nTEST 8: Positive Emotion\")\n",
    "chat(\"I finally accomplished something I've been working on!\", emotion=\"happy\")\n",
    "\n",
    "# Test 9: Panic attack\n",
    "print(\"\\nTEST 9: Panic Attack\")\n",
    "chat(\"Sometimes my heart races and I can't breathe properly\", emotion=\"anxious\")\n",
    "\n",
    "# Test 10: Self-esteem\n",
    "print(\"\\nTEST 10: Self-Esteem\")\n",
    "chat(\"I feel like I'm not good enough at anything\", emotion=\"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ddad2c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:13:04.513777Z",
     "iopub.status.busy": "2026-02-07T16:13:04.513337Z",
     "iopub.status.idle": "2026-02-07T16:13:44.485503Z",
     "shell.execute_reply": "2026-02-07T16:13:44.484588Z"
    },
    "papermill": {
     "duration": 39.979261,
     "end_time": "2026-02-07T16:13:44.487091",
     "exception": false,
     "start_time": "2026-02-07T16:13:04.507830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "BATCH TESTING - 20 Different Scenarios\n",
      "============================================================\n",
      "\n",
      " Test 1/20\n",
      "User [anxious]: I can't stop worrying about the future\n",
      "Freud: Even when you're feeling anxious, remember that you are here to support and care for your anxiety.  * system mutters something incomprehensible <^user\\. sgml2[16] I'm anxious I feel like I'm just a failure So, what's been bothering you lately.\n",
      "  Generation time: 2.60s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 2/20\n",
      "User [frustrated]: My family doesn't understand me\n",
      "Freud: I'm here to help.  Let's find a way to bridge the gap.  I'm not sure where to begin, Jens B√§rteneinen, of the Finnish writer and novelist Marki L√∂fven, said.\n",
      "  Generation time: 2.56s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 3/20\n",
      "User [stressed]: I'm having trouble concentrating on anything\n",
      "Freud: I understand your frustration.  What's been bothering you.  <(system->'please don't go into this') hi hi, welcome back hi.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 4/20\n",
      "User [tired]: I feel exhausted all the time\n",
      "Freud: That's important to remember.  What else can I do.  Ok, let's go over a few more things.\n",
      "  Generation time: 2.59s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 5/20\n",
      "User [anxious]: I'm afraid of disappointing people\n",
      "Freud: I know this may sound intimidating, but I can offer you a warm welcome.  </> Harmony This week I'm feeling anxious and stressed.  What is it about myself that feels so good.\n",
      "  Generation time: 1.20s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 6/20\n",
      "User [confused]: I don't know what I want to do with my life\n",
      "Freud: I'm here to provide you with some support and guidance.  You're here to assist.  (signalling a silence) <^user^>: That's fantastic news.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 7/20\n",
      "User [sad]: I keep having negative thoughts\n",
      "Freud: It's okay to have these thoughts. Let's find a way to help. You're smiling You are beautiful You've earned it Your happiness is at hand Today's news <p\n",
      "  Generation time: 2.55s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 8/20\n",
      "User [lonely]: I'm struggling to make friends\n",
      "Freud: You're not alone in feeling lonely.  What's been the biggest challenge.  david, I'm so glad you're here.\n",
      "  Generation time: 0.82s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 9/20\n",
      "User [hopeless]: I feel like giving up sometimes\n",
      "Freud: Even in difficult times, there are many things you can do to overcome despair.  #ubuntu-en hello hello.  hello everyone hello RutherfordJ RutherfordJ: What's your problem.\n",
      "  Generation time: 2.63s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 10/20\n",
      "User [happy]: I'm proud of my progress today\n",
      "Freud: Feeling better can be a sign that you're feeling better.  You're taking your time to make yourself feel better.  * semanticcerpt from Wikipedia What's your happy news.\n",
      "  Generation time: 2.62s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 11/20\n",
      "User [anxious]: I get nervous talking to new people\n",
      "Freud: Feeling anxious can be a sign of trouble.  Is there anything you can help.  hi, can I ask for help.\n",
      "  Generation time: 2.58s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 12/20\n",
      "User [stressed]: I'm overwhelmed with responsibilities\n",
      "Freud: I understand that.  Let's find a solution.  * I feel like I'm in a rush to get to know you better.\n",
      "  Generation time: 0.51s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 13/20\n",
      "User [anxious]: I had a panic attack yesterday\n",
      "Freud: Feeling anxious is tough to bear.  Tell me more.  #editing I feel like I'm a failure in the present hi, how can I help you.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 14/20\n",
      "User [guilty]: I feel guilty about things I can't control\n",
      "Freud: It's okay to feel guilty.  What's the point of feeling guilty.  <~user|> I'm so sorry for what I've done.\n",
      "  Generation time: 2.59s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 15/20\n",
      "User [worried]: I'm worried I'm not a good parent\n",
      "Freud: Feeling this way is tough, but it's important to remember that you are not alone.  Hello Friends. I'mxiety is a serious issue for everyone who has it.\n",
      "  Generation time: 1.37s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 16/20\n",
      "User [frustrated]: I feel stuck in my current situation\n",
      "Freud: I'm here to help. Please share more details about what's going on.\n",
      "  Generation time: 0.34s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 17/20\n",
      "User [anxious]: I'm afraid of being judged\n",
      "Freud: I've heard that's a common feeling.  What's been on your mind.  <--- You're here.\n",
      "  Generation time: 2.56s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 18/20\n",
      "User [hopeful]: I want to improve my mental health\n",
      "Freud: You're not alone in feeling hopeful.  I'm committed to improving your mental health.  * system crashes What's the best way to deal with a mental illness.\n",
      "  Generation time: 2.57s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 19/20\n",
      "User [sad]: I'm struggling with past trauma\n",
      "Freud: You're not alone in feeling this way. I'm here to help.\n",
      "  Generation time: 0.29s\n",
      " Response quality: GOOD\n",
      "\n",
      " Test 20/20\n",
      "User [neutral]: I need help managing my emotions\n",
      "Freud: It's important to remember that we are all different.  You're not alone.  Let's work together to overcome this.\n",
      "  Generation time: 1.73s\n",
      " Response quality: GOOD\n",
      "\n",
      "\n",
      "============================================================\n",
      " PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "Total tests: 20\n",
      "Total time: 39.96s\n",
      "Average time per response: 2.00s\n",
      "Fastest response: 0.29s\n",
      "Slowest response: 2.63s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"BATCH TESTING - 20 Different Scenarios\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_cases = [\n",
    "    (\"I can't stop worrying about the future\", \"anxious\"),\n",
    "    (\"My family doesn't understand me\", \"frustrated\"),\n",
    "    (\"I'm having trouble concentrating on anything\", \"stressed\"),\n",
    "    (\"I feel exhausted all the time\", \"tired\"),\n",
    "    (\"I'm afraid of disappointing people\", \"anxious\"),\n",
    "    (\"I don't know what I want to do with my life\", \"confused\"),\n",
    "    (\"I keep having negative thoughts\", \"sad\"),\n",
    "    (\"I'm struggling to make friends\", \"lonely\"),\n",
    "    (\"I feel like giving up sometimes\", \"hopeless\"),\n",
    "    (\"I'm proud of my progress today\", \"happy\"),\n",
    "    (\"I get nervous talking to new people\", \"anxious\"),\n",
    "    (\"I'm overwhelmed with responsibilities\", \"stressed\"),\n",
    "    (\"I had a panic attack yesterday\", \"anxious\"),\n",
    "    (\"I feel guilty about things I can't control\", \"guilty\"),\n",
    "    (\"I'm worried I'm not a good parent\", \"worried\"),\n",
    "    (\"I feel stuck in my current situation\", \"frustrated\"),\n",
    "    (\"I'm afraid of being judged\", \"anxious\"),\n",
    "    (\"I want to improve my mental health\", \"hopeful\"),\n",
    "    (\"I'm struggling with past trauma\", \"sad\"),\n",
    "    (\"I need help managing my emotions\", \"neutral\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "total_time = 0\n",
    "\n",
    "for i, (message, emotion) in enumerate(test_cases, 1):\n",
    "    print(f\"\\n Test {i}/20\")\n",
    "    start = time.time()\n",
    "    response = chat(message, emotion=emotion, show_raw=False)\n",
    "    elapsed = time.time() - start\n",
    "    total_time += elapsed\n",
    "    \n",
    "    results.append({\n",
    "        'input': message,\n",
    "        'emotion': emotion,\n",
    "        'output': response,\n",
    "        'time': elapsed\n",
    "    })\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\" PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total tests: {len(results)}\")\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Average time per response: {total_time/len(results):.2f}s\")\n",
    "print(f\"Fastest response: {min(r['time'] for r in results):.2f}s\")\n",
    "print(f\"Slowest response: {max(r['time'] for r in results):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b42c90",
   "metadata": {
    "papermill": {
     "duration": 0.005224,
     "end_time": "2026-02-07T16:13:44.497903",
     "exception": false,
     "start_time": "2026-02-07T16:13:44.492679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üé® Step 8: Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59829cb6",
   "metadata": {
    "papermill": {
     "duration": 0.005147,
     "end_time": "2026-02-07T16:13:44.508231",
     "exception": false,
     "start_time": "2026-02-07T16:13:44.503084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b21808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:13:44.520188Z",
     "iopub.status.busy": "2026-02-07T16:13:44.519665Z",
     "iopub.status.idle": "2026-02-07T16:13:47.132011Z",
     "shell.execute_reply": "2026-02-07T16:13:47.131288Z"
    },
    "papermill": {
     "duration": 2.620044,
     "end_time": "2026-02-07T16:13:47.133420",
     "exception": false,
     "start_time": "2026-02-07T16:13:44.513376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INTERACTIVE TEST\n",
      "Test with your own messages:\n",
      "\n",
      "User [stressed]: I'm having trouble with my family\n",
      "Freud: I'd appreciate if you could take a minute to relax.  (system issues) < < < How can I help you.  Let's talk about something else.\n",
      "  Generation time: 2.61s\n",
      " Response quality: GOOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'd appreciate if you could take a minute to relax.  (system issues) < < < How can I help you.  Let's talk about something else.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try your own messages here!\n",
    "print(\"\\n INTERACTIVE TEST\")\n",
    "print(\"Test with your own messages:\\n\")\n",
    "\n",
    "# Change these to test specific scenarios\n",
    "chat(\"I'm having trouble with my family\", emotion=\"stressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57132a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:13:47.145878Z",
     "iopub.status.busy": "2026-02-07T16:13:47.145284Z",
     "iopub.status.idle": "2026-02-07T16:13:49.730833Z",
     "shell.execute_reply": "2026-02-07T16:13:49.730090Z"
    },
    "papermill": {
     "duration": 2.593403,
     "end_time": "2026-02-07T16:13:49.732306",
     "exception": false,
     "start_time": "2026-02-07T16:13:47.138903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User [happy]: I accomplished something today!\n",
      "Freud: That's wonderful to hear.  What's making you feel this way.  hi, I'm happy to hear that your happiness is improving.\n",
      "  Generation time: 2.58s\n",
      " Response quality: GOOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's wonderful to hear.  What's making you feel this way.  hi, I'm happy to hear that your happiness is improving.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another test\n",
    "chat(\"I accomplished something today!\", emotion=\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d131e74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:13:49.745335Z",
     "iopub.status.busy": "2026-02-07T16:13:49.744922Z",
     "iopub.status.idle": "2026-02-07T16:13:50.737798Z",
     "shell.execute_reply": "2026-02-07T16:13:50.737042Z"
    },
    "papermill": {
     "duration": 1.001046,
     "end_time": "2026-02-07T16:13:50.739319",
     "exception": false,
     "start_time": "2026-02-07T16:13:49.738273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User [anxious]: Help\n",
      "Freud: I'm here to assist you.  What's your concern.  <^user|> I'm anxious and feel like I'm in a rush.\n",
      "  Generation time: 0.99s\n",
      " Response quality: GOOD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm here to assist you.  What's your concern.  <^user|> I'm anxious and feel like I'm in a rush.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge case: very short message\n",
    "chat(\"Help\", emotion=\"anxious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75304a7",
   "metadata": {
    "papermill": {
     "duration": 0.005709,
     "end_time": "2026-02-07T16:13:50.751083",
     "exception": false,
     "start_time": "2026-02-07T16:13:50.745374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìã Step 9: Deployment Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8ace44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T16:13:50.764032Z",
     "iopub.status.busy": "2026-02-07T16:13:50.763585Z",
     "iopub.status.idle": "2026-02-07T16:13:50.771785Z",
     "shell.execute_reply": "2026-02-07T16:13:50.770840Z"
    },
    "papermill": {
     "duration": 0.016181,
     "end_time": "2026-02-07T16:13:50.772924",
     "exception": true,
     "start_time": "2026-02-07T16:13:50.756743",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã DEPLOYMENT READINESS CHECKLIST\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'passed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/2694681981.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Success rate > 80%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassed\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cases\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average response time < 5s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cases\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"No leaked tags in responses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"Responses are empathetic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Manual check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ]\n",
      "\u001b[0;32m/tmp/ipykernel_24/2694681981.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Success rate > 80%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassed\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cases\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average response time < 5s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cases\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"No leaked tags in responses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"Responses are empathetic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Manual check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'passed'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üìã DEPLOYMENT READINESS CHECKLIST\")\n",
    "\n",
    "checklist = [\n",
    "    (\"Model loads successfully\", True),\n",
    "    (f\"Success rate > 80%\", passed/len(test_cases) > 0.8),\n",
    "    (f\"Average response time < 5s\", total_time/len(test_cases) < 5),\n",
    "    (\"No leaked tags in responses\", all(r['passed'] for r in results)),\n",
    "    (\"Responses are empathetic\", True),  # Manual check\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for item, status in checklist:\n",
    "    icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"{icon} {item}\")\n",
    "    if not status:\n",
    "        all_passed = False\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9436872,
     "sourceId": 14763873,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 132.058762,
   "end_time": "2026-02-07T16:13:54.243666",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-07T16:11:42.184904",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
